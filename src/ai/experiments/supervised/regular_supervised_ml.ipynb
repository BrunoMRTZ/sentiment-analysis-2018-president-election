{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:37:48.105997Z",
     "start_time": "2018-11-02T11:37:48.079523Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import copy\n",
    "import re\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from utils import tokenizer, load_six_emotions, load_3_emotions\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Para validar, serão utilizados dois datasets.\n",
    "\n",
    "O primeiro deles foi fornecido a nós pela Barbara Martinazzo, e contém cerca de 1000 frases categorizadas entre as 6 emoções do Ekman (alegria, surpresa, tristeza, medo, raiva, desgosto).\n",
    "\n",
    "O segundo dataset, contém também cerca de 1000 frases, também categorizados usando as 6 emoções conforme o anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:31:48.490280Z",
     "start_time": "2018-11-02T11:31:15.014951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ALEGRIA', 'moviment lgbt faz manifest ramp congress açã acontec durant seminári sobr tem particip ped criminaliz homofob'), ('ALEGRIA', 'bid dar empréstim us bilhõ méxic grip cris emprést quas tripl valor oferec objet ameniz impact grip cris econôm'), ('DESGOSTO', 'berzoin cham empresári demit precis ladrõ president pt particip fest dia trabalh cut jos genoín particip event central'), ('TRISTEZA', 'grup troc tir políc após roub banc rs segund inform brig milit cofr lev ladrõ nenhum suspeit pres esta terc feir'), ('TRISTEZA', 'rendiment fix poupanc pod imped reduçã jur cas própr cadernet rendiment fix garant lei ano percentual serv jur mínim crédit imobiliári')]\n"
     ]
    }
   ],
   "source": [
    "def carregar(filename):\n",
    "    frases = []\n",
    "    with open(filename, 'r') as h:\n",
    "        reader = csv.reader(h, delimiter=';')\n",
    "        for row in reader:\n",
    "            frase = tokenizer(row[0]).strip()\n",
    "            sentimento = row[1].upper()\n",
    "            if len(frase) > 5:\n",
    "                frases.append((sentimento, frase))\n",
    "    return frases\n",
    "\n",
    "frases = carregar('/home/rdenadai/vagrant/python-dev/sentiment-analysis-2018-president-election/dataset/puc-pr/politica.csv')\n",
    "frases += carregar('/home/rdenadai/vagrant/python-dev/sentiment-analysis-2018-president-election/dataset/puc-pr/g1_v1.csv')\n",
    "\n",
    "shuffle(frases)\n",
    "\n",
    "print(frases[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:32:15.893127Z",
     "start_time": "2018-11-02T11:32:15.883827Z"
    }
   },
   "outputs": [],
   "source": [
    "afrases = []\n",
    "asentimentos =[]\n",
    "for sentimento, frase in frases:\n",
    "    afrases.append(frase)\n",
    "    asentimentos.append(sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:43:18.005309Z",
     "start_time": "2018-11-02T11:43:17.986846Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_ml_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = np.round(model.score(X_test, y_test) * 100, 2)\n",
    "    print(f'Modelo   : {model.__class__.__name__}')\n",
    "    print(f'Acurácia : {accuracy}%')\n",
    "    print('-' * 20)\n",
    "    return accuracy\n",
    "\n",
    "def split_data(X, y):\n",
    "    test_size = .33\n",
    "    random_state = 0\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:43:20.278224Z",
     "start_time": "2018-11-02T11:43:20.250699Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = (\n",
    "    LogisticRegression(multi_class='auto', solver='lbfgs'),\n",
    "    RandomForestClassifier(n_estimators=20),\n",
    "    LinearSVC(max_iter=1500),\n",
    "    MultinomialNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    MLPClassifier(max_iter=500),\n",
    "    SVC(gamma='auto', max_iter=1500),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:43:20.958049Z",
     "start_time": "2018-11-02T11:43:20.833674Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_tfidf = vec_tfidf.fit_transform(afrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:44:06.630102Z",
     "start_time": "2018-11-02T11:43:21.468957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 56.65%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 60.57%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 60.42%\n",
      "--------------------\n",
      "Modelo   : MultinomialNB\n",
      "Acurácia : 55.59%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 48.04%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 59.52%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 35.2%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_tfidf, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA (usando TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:44:12.334329Z",
     "start_time": "2018-11-02T11:44:06.632029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 42.45%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 57.7%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 43.66%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 36.4%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 42.75%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 36.25%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "X_svd = svd.fit_transform(X_tfidf)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_svd, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (usando TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:44:18.290083Z",
     "start_time": "2018-11-02T11:44:12.336586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 34.14%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 53.78%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 34.29%\n",
      "--------------------\n",
      "Modelo   : MultinomialNB\n",
      "Acurácia : 35.2%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 35.95%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 35.2%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 35.2%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "X_lda = lda.fit_transform(X_tfidf)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_lda, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:44:18.448882Z",
     "start_time": "2018-11-02T11:44:18.292521Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_count = CountVectorizer(ngram_range=(1, 2))\n",
    "X_count = vec_count.fit_transform(afrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:44:48.448087Z",
     "start_time": "2018-11-02T11:44:18.450607Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 61.78%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 58.46%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 61.78%\n",
      "--------------------\n",
      "Modelo   : MultinomialNB\n",
      "Acurácia : 57.7%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 30.36%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 59.06%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 35.2%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_count, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA (usando Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:44:56.046928Z",
     "start_time": "2018-11-02T11:44:48.449778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 39.58%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 56.65%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 39.88%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 41.99%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 41.99%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 41.24%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "X_svd = svd.fit_transform(X_count)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_svd, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (usando Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T11:45:03.703912Z",
     "start_time": "2018-11-02T11:44:56.048628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 35.2%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 54.23%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 35.2%\n",
      "--------------------\n",
      "Modelo   : MultinomialNB\n",
      "Acurácia : 35.2%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 37.46%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 35.2%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 35.2%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "X_lda = lda.fit_transform(X_count)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_lda, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "31px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
