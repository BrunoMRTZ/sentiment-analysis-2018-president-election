{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:16:30.734086Z",
     "start_time": "2018-11-05T00:16:30.720539Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import copy\n",
    "import re\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from utils import tokenizer, load_six_emotions, load_3_emotions\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Para validar, serão utilizados dois datasets.\n",
    "\n",
    "O primeiro deles foi fornecido a nós pela Barbara Martinazzo, e contém cerca de 1000 frases categorizadas entre as 6 emoções do Ekman (alegria, surpresa, tristeza, medo, raiva, desgosto).\n",
    "\n",
    "O segundo dataset, contém também cerca de 1000 frases, também categorizados usando as 6 emoções conforme o anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:16:36.495673Z",
     "start_time": "2018-11-05T00:16:31.481099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ALEGRIA', 'encomend indústr eua caem mais previst marc baix sétim desvaloriz oit mes dad fevereir revis alta'), ('TRISTEZA', 'alco registr prejuíz milhõ trimestr fabric alumíni inaugur tempor balanc eua prejuíz açã entretant fic abaix esper anal'), ('ALEGRIA', 'fisc destro forn carvã ileg par agent aind flagr florest send desmat imagens satélit der iníci açã'), ('TRISTEZA', 'estud indic chimpanzés capaz aprec músic pesquis filhot revel animal prefer ouv músic harmoni'), ('DESGOSTO', 'rom tum diz nã deix corregedor sen afast funçã ped alguns senador diretor acus tum envolv fraud contrat')]\n"
     ]
    }
   ],
   "source": [
    "def carregar(filename):\n",
    "    frases = []\n",
    "    with open(filename, 'r') as h:\n",
    "        reader = csv.reader(h, delimiter=';')\n",
    "        for row in reader:\n",
    "            frase = tokenizer(row[0]).strip()\n",
    "            sentimento = row[1].upper()\n",
    "            if len(frase) > 5:\n",
    "                frases.append((sentimento, frase))\n",
    "    return frases\n",
    "\n",
    "frases = carregar('/home/rdenadai/vagrant/python-dev/sentiment-analysis-2018-president-election/dataset/puc-pr/politica.csv')\n",
    "frases += carregar('/home/rdenadai/vagrant/python-dev/sentiment-analysis-2018-president-election/dataset/puc-pr/g1_v1.csv')\n",
    "\n",
    "shuffle(frases)\n",
    "\n",
    "print(frases[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:16:36.505512Z",
     "start_time": "2018-11-05T00:16:36.498134Z"
    }
   },
   "outputs": [],
   "source": [
    "afrases = []\n",
    "asentimentos =[]\n",
    "for sentimento, frase in frases:\n",
    "    afrases.append(frase)\n",
    "    asentimentos.append(sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:16:36.596367Z",
     "start_time": "2018-11-05T00:16:36.508171Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_ml_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = np.round(model.score(X_test, y_test) * 100, 2)\n",
    "    print(f'Modelo   : {model.__class__.__name__}')\n",
    "    print(f'Acurácia : {accuracy}%')\n",
    "    print('-' * 20)\n",
    "    return accuracy\n",
    "\n",
    "def split_data(X, y):\n",
    "    test_size = .33\n",
    "    random_state = 0\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:16:36.714638Z",
     "start_time": "2018-11-05T00:16:36.602461Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = (\n",
    "    LogisticRegression(multi_class='auto', solver='lbfgs'),\n",
    "    RandomForestClassifier(n_estimators=25),\n",
    "    LinearSVC(max_iter=1500),\n",
    "    MultinomialNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    MLPClassifier(max_iter=1500),\n",
    "    SVC(gamma='auto', max_iter=1500),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:16:36.932263Z",
     "start_time": "2018-11-05T00:16:36.721312Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_tfidf = vec_tfidf.fit_transform(afrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:17:21.725987Z",
     "start_time": "2018-11-05T00:16:36.934073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 55.14%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 58.16%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 59.97%\n",
      "--------------------\n",
      "Modelo   : MultinomialNB\n",
      "Acurácia : 54.98%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 44.41%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 60.73%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.14%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_tfidf, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA (usando TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:17:37.392211Z",
     "start_time": "2018-11-05T00:17:21.728328Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 42.75%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 54.83%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 44.71%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 41.99%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 46.68%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 35.2%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "X_svd = svd.fit_transform(X_tfidf)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_svd, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (usando TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:17:44.151517Z",
     "start_time": "2018-11-05T00:17:37.394589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 34.14%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 52.11%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 34.14%\n",
      "--------------------\n",
      "Modelo   : MultinomialNB\n",
      "Acurácia : 34.14%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 33.38%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 34.14%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.14%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "X_lda = lda.fit_transform(X_tfidf)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_lda, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:17:44.249826Z",
     "start_time": "2018-11-05T00:17:44.153537Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_count = CountVectorizer(ngram_range=(1, 2))\n",
    "X_count = vec_count.fit_transform(afrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:18:30.216109Z",
     "start_time": "2018-11-05T00:17:44.251425Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 59.67%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 59.67%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 58.61%\n",
      "--------------------\n",
      "Modelo   : MultinomialNB\n",
      "Acurácia : 56.19%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 6.8%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 59.52%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.14%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_count, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA (usando Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:18:51.198136Z",
     "start_time": "2018-11-05T00:18:30.218238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 41.24%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 52.87%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 41.39%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 36.86%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 42.45%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 38.97%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "X_svd = svd.fit_transform(X_count)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_svd, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (usando Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T00:18:59.910715Z",
     "start_time": "2018-11-05T00:18:51.199709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 34.14%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 54.68%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 34.14%\n",
      "--------------------\n",
      "Modelo   : MultinomialNB\n",
      "Acurácia : 34.14%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 36.71%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 34.14%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.14%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "X_lda = lda.fit_transform(X_count)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        run_ml_model(classifier, **split_data(X_lda, asentimentos))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "31px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
