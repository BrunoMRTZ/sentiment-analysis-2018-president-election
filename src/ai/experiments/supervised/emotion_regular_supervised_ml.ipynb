{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:41:57.821194Z",
     "start_time": "2018-11-24T17:41:55.036343Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import copy\n",
    "import re\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from utils import tokenizer, load_six_emotions, load_3_emotions\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "np.random.seed(12345)\n",
    "\n",
    "def highlight_max(data, color='green'):\n",
    "    attr = f'background-color: {color}; color: white; font-weight: bold;'\n",
    "    #remove % and cast to float\n",
    "    data = data.replace('%','', regex=True).astype(float)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else '' for v in is_max]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_max = data == data.max().max()\n",
    "        return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                            index=data.index, columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:41:57.831653Z",
     "start_time": "2018-11-24T17:41:57.823897Z"
    }
   },
   "outputs": [],
   "source": [
    "classf = {\n",
    "    'MultinomialNB': 0,\n",
    "    'ComplementNB': 0,\n",
    "    'LogisticRegression': 0,\n",
    "    'RandomForestClassifier': 0,\n",
    "    'KNeighborsClassifier': 0,\n",
    "    'MLPClassifier': 0,\n",
    "    'LinearSVC': 0,\n",
    "    'SVC': 0\n",
    "}\n",
    "\n",
    "matriz_resultados = {\n",
    "    'tfidf': copy.deepcopy(classf),\n",
    "    'tfidf+lsa': copy.deepcopy(classf),\n",
    "    'tfidf+lda': copy.deepcopy(classf),\n",
    "    'count': copy.deepcopy(classf),\n",
    "    'count+lsa': copy.deepcopy(classf),\n",
    "    'count+lda': copy.deepcopy(classf),\n",
    "    'tfidf+count+w2c': copy.deepcopy(classf),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Fornecido pela equipe da PUC-PR através do site [EMOÇÕES.BR](http://www.ppgia.pucpr.br/~paraiso/mineracaodeemocoes/index.php), contém cerca de 1000 frases, categorizadas usando as 6 emoções de Ekman (alegria, surpresa, tristeza, medo, raiva, desgosto).\n",
    "Alem disso, foi acrescido em torno de 700 novas frases rotuladas, totalizando 1720 frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:42:03.928703Z",
     "start_time": "2018-11-24T17:41:57.833895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TRISTEZA', 'errar acredit cad errar nã acredit ninguém'), ('TRISTEZA', 'necess melhor mestr gui natur necess tern inventor etern frei lei natur'), ('TRISTEZA', 'dois erro vid vir fat sent dev pens pens dev sent'), ('NEUTRO', 'volt petr csn caf ferr'), ('ALEGRIA', 'alenc caminh comed aliment nest segund diz hospital vic submet cirurg sext trat obstruçã intestinal médic diz vic president evolu bem')]\n"
     ]
    }
   ],
   "source": [
    "def carregar(filename):\n",
    "    frases = []\n",
    "    with open(filename, 'r') as h:\n",
    "        reader = csv.reader(h, delimiter='|')\n",
    "        for row in reader:\n",
    "            frase = tokenizer(row[0]).strip()\n",
    "            sentimento = row[1].upper()\n",
    "            if len(frase) > 5:\n",
    "                frases.append((sentimento, frase))\n",
    "    return frases\n",
    "\n",
    "frases = carregar('/home/rdenadai/vagrant/python-dev/sentiment-analysis-2018-president-election/dataset/frases/frases_todas.txt')\n",
    "\n",
    "shuffle(frases)\n",
    "print(frases[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:42:03.934284Z",
     "start_time": "2018-11-24T17:42:03.930550Z"
    }
   },
   "outputs": [],
   "source": [
    "afrases = []\n",
    "asentimentos =[]\n",
    "for sentimento, frase in frases:\n",
    "    afrases.append(frase)\n",
    "    asentimentos.append(sentimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de Apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:42:04.073328Z",
     "start_time": "2018-11-24T17:42:03.937654Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_ml_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = np.round(model.score(X_test, y_test) * 100, 2)\n",
    "    print(f'Modelo   : {model.__class__.__name__}')\n",
    "    print(f'Acurácia : {accuracy}%')\n",
    "    print('-' * 20)\n",
    "    return accuracy\n",
    "\n",
    "def split_data(X, y):\n",
    "    test_size = .33\n",
    "    random_state = 0\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:42:04.150467Z",
     "start_time": "2018-11-24T17:42:04.078600Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = (\n",
    "    MultinomialNB(),\n",
    "    ComplementNB(),\n",
    "    LogisticRegression(multi_class='auto', solver='lbfgs'),\n",
    "    RandomForestClassifier(n_estimators=50, min_samples_split=8, random_state=0),\n",
    "    KNeighborsClassifier(n_neighbors=8, algorithm='auto'),\n",
    "    MLPClassifier(hidden_layer_sizes=(100, 25), max_iter=500, random_state=0),\n",
    "    LinearSVC(max_iter=500),\n",
    "    SVC(gamma='auto', max_iter=500),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:42:04.439220Z",
     "start_time": "2018-11-24T17:42:04.157846Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_tfidf = vec_tfidf.fit_transform(afrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:43:10.283477Z",
     "start_time": "2018-11-24T17:42:04.440859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 50.19%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 52.66%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 53.66%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 53.53%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 51.18%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 53.41%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 55.27%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 28.0%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_tfidf, asentimentos))\n",
    "        matriz_resultados['tfidf'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA (usando TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:43:21.820903Z",
     "start_time": "2018-11-24T17:43:10.285293Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 28.0%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 43.99%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 54.77%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 53.04%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 46.22%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 53.78%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 54.4%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 28.0%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=70, n_iter=50, random_state=0)\n",
    "normalizer = MinMaxScaler(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "X_svd = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_svd, asentimentos))\n",
    "        matriz_resultados['tfidf+lsa'][classifier.__class__.__name__] = acc\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (usando TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:43:56.103747Z",
     "start_time": "2018-11-24T17:43:21.822582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 27.39%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 21.31%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 27.63%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 34.32%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 28.87%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 30.11%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 25.65%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 28.0%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=70, max_iter=50, random_state=0, n_jobs=5)\n",
    "normalizer = MinMaxScaler(copy=False)\n",
    "lda = make_pipeline(lda, normalizer)\n",
    "X_lda = lda.fit_transform(X_tfidf)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_lda, asentimentos))\n",
    "        matriz_resultados['tfidf+lda'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:43:56.219463Z",
     "start_time": "2018-11-24T17:43:56.105759Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_count = CountVectorizer(ngram_range=(1, 2))\n",
    "X_count = vec_count.fit_transform(afrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:44:53.789539Z",
     "start_time": "2018-11-24T17:43:56.221029Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 54.89%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 47.58%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 55.89%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 54.15%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 28.38%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 51.43%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 53.04%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 28.0%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_count, asentimentos))\n",
    "        matriz_resultados['count'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA (usando Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:45:03.665863Z",
     "start_time": "2018-11-24T17:44:53.791571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 28.0%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 33.83%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 50.68%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 49.94%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 41.26%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 50.56%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 50.56%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 28.0%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=70, n_iter=50, random_state=0)\n",
    "normalizer = MinMaxScaler(copy=False)\n",
    "lda = make_pipeline(svd, normalizer)\n",
    "X_svd = lda.fit_transform(X_count)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_svd, asentimentos))\n",
    "        matriz_resultados['count+lsa'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (usando Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:45:34.206893Z",
     "start_time": "2018-11-24T17:45:03.667620Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 28.87%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 19.83%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 29.12%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 28.5%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 29.0%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 30.73%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 28.0%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 28.0%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=70, max_iter=50, random_state=0, n_jobs=5)\n",
    "normalizer = MinMaxScaler(copy=False)\n",
    "lda = make_pipeline(lda, normalizer)\n",
    "X_lda = lda.fit_transform(X_count)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_lda, asentimentos))\n",
    "        matriz_resultados['count+lda'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count + TF-IDF + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:48:39.708609Z",
     "start_time": "2018-11-24T17:45:34.208671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29458352, 31096000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count\n",
    "vec_count = CountVectorizer()\n",
    "X_count = vec_count.fit_transform(afrases)\n",
    "weights_count = pd.DataFrame(np.round(X_count.toarray().T, 8), index=vec_count.get_feature_names())\n",
    "\n",
    "# TF-IDF\n",
    "vec_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vec_tfidf.fit_transform(afrases)\n",
    "weights_tfidf = pd.DataFrame(np.round(X_tfidf.toarray().T, 8), index=vec_tfidf.get_feature_names())\n",
    "\n",
    "# Word2Vec preprocessing\n",
    "frases_w2v = []\n",
    "for frase in afrases:\n",
    "    bigram = []\n",
    "    p_frase = word_tokenize(frase)\n",
    "    for m, palavra in enumerate(p_frase):\n",
    "        next_p = None\n",
    "        try:\n",
    "            next_p = p_frase[m+1]\n",
    "        except:\n",
    "            pass\n",
    "        bigram += [f'{palavra}']\n",
    "#         if next_p:\n",
    "#             bigram += [f'{palavra} {next_p}']\n",
    "    frases_w2v += [bigram]\n",
    "\n",
    "# Word2Vec\n",
    "model = gensim.models.Word2Vec(\n",
    "    sentences=frases_w2v,\n",
    "    sg=1,\n",
    "    hs=1,\n",
    "    size=1,\n",
    "    window=25,\n",
    "    min_count=1,\n",
    "    seed=0,\n",
    "    workers=10)\n",
    "model.train(frases_w2v, total_examples=len(frases_w2v), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:48:41.015579Z",
     "start_time": "2018-11-24T17:48:39.713397Z"
    }
   },
   "outputs": [],
   "source": [
    "r_words = {}\n",
    "for word in vec_count.get_feature_names():\n",
    "    idx = weights_count.index.get_loc(word)\n",
    "    w2c_val = .1\n",
    "    try:\n",
    "        w2c_val = model.wv[word]\n",
    "    except:\n",
    "        pass\n",
    "    r_words[word] = (weights_tfidf.iloc[idx].values + weights_count.iloc[idx].values) * w2c_val\n",
    "lwor = list(r_words.keys())\n",
    "X = np.asarray(list(r_words.values()))\n",
    "weights = pd.DataFrame(X, index=lwor)\n",
    "X = X.T\n",
    "\n",
    "normalizer = Normalizer(copy=False)\n",
    "X = normalizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:50:17.757077Z",
     "start_time": "2018-11-24T17:48:41.017633Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 55.76%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 55.14%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 47.83%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 50.56%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 52.91%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 28.0%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X, asentimentos))\n",
    "        matriz_resultados['tfidf+count+w2c'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado dos Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:50:17.841263Z",
     "start_time": "2018-11-24T17:50:17.759976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_679e88bc_f011_11e8_af9c_5cc9d364484drow2_col0 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col1 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col3 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col4 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col6 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_679e88bc_f011_11e8_af9c_5cc9d364484drow4_col5 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_679e88bc_f011_11e8_af9c_5cc9d364484drow6_col2 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }</style>  \n",
       "<table id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484d\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >tfidf</th> \n",
       "        <th class=\"col_heading level0 col1\" >tfidf+lsa</th> \n",
       "        <th class=\"col_heading level0 col2\" >tfidf+lda</th> \n",
       "        <th class=\"col_heading level0 col3\" >count</th> \n",
       "        <th class=\"col_heading level0 col4\" >count+lsa</th> \n",
       "        <th class=\"col_heading level0 col5\" >count+lda</th> \n",
       "        <th class=\"col_heading level0 col6\" >tfidf+count+w2c</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484dlevel0_row0\" class=\"row_heading level0 row0\" >ComplementNB</th> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow0_col0\" class=\"data row0 col0\" >52.66%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow0_col1\" class=\"data row0 col1\" >43.99%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow0_col2\" class=\"data row0 col2\" >21.31%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow0_col3\" class=\"data row0 col3\" >47.58%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow0_col4\" class=\"data row0 col4\" >33.83%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow0_col5\" class=\"data row0 col5\" >19.83%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow0_col6\" class=\"data row0 col6\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484dlevel0_row1\" class=\"row_heading level0 row1\" >KNeighborsClassifier</th> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow1_col0\" class=\"data row1 col0\" >51.18%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow1_col1\" class=\"data row1 col1\" >46.22%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow1_col2\" class=\"data row1 col2\" >28.87%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow1_col3\" class=\"data row1 col3\" >28.38%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow1_col4\" class=\"data row1 col4\" >41.26%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow1_col5\" class=\"data row1 col5\" >29.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow1_col6\" class=\"data row1 col6\" >47.83%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484dlevel0_row2\" class=\"row_heading level0 row2\" >LinearSVC</th> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow2_col0\" class=\"data row2 col0\" >55.27%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow2_col1\" class=\"data row2 col1\" >54.40%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow2_col2\" class=\"data row2 col2\" >25.65%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow2_col3\" class=\"data row2 col3\" >53.04%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow2_col4\" class=\"data row2 col4\" >50.56%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow2_col5\" class=\"data row2 col5\" >28.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow2_col6\" class=\"data row2 col6\" >52.91%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484dlevel0_row3\" class=\"row_heading level0 row3\" >LogisticRegression</th> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col0\" class=\"data row3 col0\" >53.66%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col1\" class=\"data row3 col1\" >54.77%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col2\" class=\"data row3 col2\" >27.63%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col3\" class=\"data row3 col3\" >55.89%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col4\" class=\"data row3 col4\" >50.68%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col5\" class=\"data row3 col5\" >29.12%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow3_col6\" class=\"data row3 col6\" >55.76%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484dlevel0_row4\" class=\"row_heading level0 row4\" >MLPClassifier</th> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow4_col0\" class=\"data row4 col0\" >53.41%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow4_col1\" class=\"data row4 col1\" >53.78%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow4_col2\" class=\"data row4 col2\" >30.11%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow4_col3\" class=\"data row4 col3\" >51.43%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow4_col4\" class=\"data row4 col4\" >50.56%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow4_col5\" class=\"data row4 col5\" >30.73%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow4_col6\" class=\"data row4 col6\" >50.56%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484dlevel0_row5\" class=\"row_heading level0 row5\" >MultinomialNB</th> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow5_col0\" class=\"data row5 col0\" >50.19%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow5_col1\" class=\"data row5 col1\" >28.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow5_col2\" class=\"data row5 col2\" >27.39%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow5_col3\" class=\"data row5 col3\" >54.89%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow5_col4\" class=\"data row5 col4\" >28.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow5_col5\" class=\"data row5 col5\" >28.87%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow5_col6\" class=\"data row5 col6\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484dlevel0_row6\" class=\"row_heading level0 row6\" >RandomForestClassifier</th> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow6_col0\" class=\"data row6 col0\" >53.53%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow6_col1\" class=\"data row6 col1\" >53.04%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow6_col2\" class=\"data row6 col2\" >34.32%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow6_col3\" class=\"data row6 col3\" >54.15%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow6_col4\" class=\"data row6 col4\" >49.94%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow6_col5\" class=\"data row6 col5\" >28.50%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow6_col6\" class=\"data row6 col6\" >55.14%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484dlevel0_row7\" class=\"row_heading level0 row7\" >SVC</th> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow7_col0\" class=\"data row7 col0\" >28.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow7_col1\" class=\"data row7 col1\" >28.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow7_col2\" class=\"data row7 col2\" >28.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow7_col3\" class=\"data row7 col3\" >28.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow7_col4\" class=\"data row7 col4\" >28.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow7_col5\" class=\"data row7 col5\" >28.00%</td> \n",
       "        <td id=\"T_679e88bc_f011_11e8_af9c_5cc9d364484drow7_col6\" class=\"data row7 col6\" >28.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2ce80cd5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(matriz_resultados)\n",
    "df.style.apply(highlight_max).format({\n",
    "    'tfidf': '{:,.2f}%'.format,\n",
    "    'tfidf+lsa': '{:,.2f}%'.format,\n",
    "    'tfidf+lda': '{:,.2f}%'.format,\n",
    "    'count': '{:,.2f}%'.format,\n",
    "    'count+lsa': '{:,.2f}%'.format,\n",
    "    'count+lda': '{:,.2f}%'.format,\n",
    "    'tfidf+count+w2c': '{:,.2f}%'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo escolhido e salvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:50:24.324478Z",
     "start_time": "2018-11-24T17:50:17.843173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : CalibratedClassifierCV\n",
      "Acurácia : 57.61%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_emotions.sav']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_tfidf = vec_tfidf.fit_transform(afrases)\n",
    "\n",
    "svd = TruncatedSVD(n_components=70, n_iter=50, random_state=0)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "X_svd = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "svm = LinearSVC(max_iter=1200)\n",
    "model = CalibratedClassifierCV(svm) \n",
    "model.fit(X_svd, asentimentos)\n",
    "\n",
    "accuracy = np.round(model.score(X_svd, asentimentos) * 100, 2)\n",
    "print(f'Modelo   : {model.__class__.__name__}')\n",
    "print(f'Acurácia : {accuracy}%')\n",
    "\n",
    "filename = 'tfidf_emotions.sav'\n",
    "joblib.dump(vec_tfidf, filename)\n",
    "\n",
    "filename = 'lsa_emotions.sav'\n",
    "joblib.dump(lsa, filename)\n",
    "\n",
    "filename = 'model_emotions.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T17:50:24.354621Z",
     "start_time": "2018-11-24T17:50:24.327210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09, 8.85, 3.11, 5.74, 4.79, 14.86, 7.71, 54.84]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict_proba(X_svd)\n",
    "list(np.round(y[0] * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "31px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
