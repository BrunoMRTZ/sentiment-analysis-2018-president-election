{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:40:15.644510Z",
     "start_time": "2018-11-23T00:40:15.622533Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import copy\n",
    "import re\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from utils import tokenizer, load_six_emotions, load_3_emotions\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "np.random.seed(12345)\n",
    "\n",
    "def highlight_max(data, color='green'):\n",
    "    attr = f'background-color: {color}; color: white; font-weight: bold;'\n",
    "    #remove % and cast to float\n",
    "    data = data.replace('%','', regex=True).astype(float)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else '' for v in is_max]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_max = data == data.max().max()\n",
    "        return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                            index=data.index, columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:15:35.119315Z",
     "start_time": "2018-11-23T00:15:35.106868Z"
    }
   },
   "outputs": [],
   "source": [
    "classf = {\n",
    "    'MultinomialNB': 0,\n",
    "    'ComplementNB': 0,\n",
    "    'LogisticRegression': 0,\n",
    "    'RandomForestClassifier': 0,\n",
    "    'KNeighborsClassifier': 0,\n",
    "    'MLPClassifier': 0,\n",
    "    'LinearSVC': 0,\n",
    "    'SVC': 0\n",
    "}\n",
    "\n",
    "matriz_resultados = {\n",
    "    'tfidf': copy.deepcopy(classf),\n",
    "    'tfidf+lsa': copy.deepcopy(classf),\n",
    "    'tfidf+lda': copy.deepcopy(classf),\n",
    "    'count': copy.deepcopy(classf),\n",
    "    'count+lsa': copy.deepcopy(classf),\n",
    "    'count+lda': copy.deepcopy(classf),\n",
    "    'tfidf+count+w2c': copy.deepcopy(classf),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Fornecido pela equipe da PUC-PR através do site [EMOÇÕES.BR](http://www.ppgia.pucpr.br/~paraiso/mineracaodeemocoes/index.php), contém cerca de 1000 frases, categorizadas usando as 6 emoções de Ekman (alegria, surpresa, tristeza, medo, raiva, desgosto).\n",
    "Alem disso, foi acrescido em torno de 700 novas frases rotuladas, totalizando 1720 frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:15:40.262201Z",
     "start_time": "2018-11-23T00:15:35.121441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SURPRESA', 'penhasc abrig cidad mort amazôn peruan cas constru sécul múm tesour pov mant tradiçã homenag falec músic com'), ('TRISTEZA', 'vez tristez nã ir embor gent aprend conviv'), ('TRISTEZA', 'negat mund nã pod derrub men permit permanec dentr'), ('ALEGRIA', 'consciênc espiã deus supervisor hom'), ('ALEGRIA', 'esperanc cresc coraçã nev ir acumul cim mur floc cad vez')]\n"
     ]
    }
   ],
   "source": [
    "def carregar(filename):\n",
    "    frases = []\n",
    "    with open(filename, 'r') as h:\n",
    "        reader = csv.reader(h, delimiter='|')\n",
    "        for row in reader:\n",
    "            frase = tokenizer(row[0]).strip()\n",
    "            sentimento = row[1].upper()\n",
    "            if len(frase) > 5:\n",
    "                frases.append((sentimento, frase))\n",
    "    return frases\n",
    "\n",
    "frases = carregar('/home/estagiario/Projetos/github/sentiment-analysis-2018-president-election/dataset/frases/frases_todas.txt')\n",
    "\n",
    "shuffle(frases)\n",
    "print(frases[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:15:40.270537Z",
     "start_time": "2018-11-23T00:15:40.265612Z"
    }
   },
   "outputs": [],
   "source": [
    "afrases = []\n",
    "asentimentos =[]\n",
    "for sentimento, frase in frases:\n",
    "    afrases.append(frase)\n",
    "    asentimentos.append(sentimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de Apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:15:40.393584Z",
     "start_time": "2018-11-23T00:15:40.273074Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_ml_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = np.round(model.score(X_test, y_test) * 100, 2)\n",
    "    print(f'Modelo   : {model.__class__.__name__}')\n",
    "    print(f'Acurácia : {accuracy}%')\n",
    "    print('-' * 20)\n",
    "    return accuracy\n",
    "\n",
    "def split_data(X, y):\n",
    "    test_size = .33\n",
    "    random_state = 0\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:15:40.505920Z",
     "start_time": "2018-11-23T00:15:40.400628Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = (\n",
    "    MultinomialNB(),\n",
    "    ComplementNB(),\n",
    "    LogisticRegression(multi_class='auto', solver='lbfgs'),\n",
    "    RandomForestClassifier(n_estimators=50, min_samples_split=8, random_state=0),\n",
    "    KNeighborsClassifier(n_neighbors=8, algorithm='auto'),\n",
    "    MLPClassifier(hidden_layer_sizes=(100, 25), max_iter=500, random_state=0),\n",
    "    LinearSVC(max_iter=500),\n",
    "    SVC(gamma='auto', max_iter=500),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:15:40.704887Z",
     "start_time": "2018-11-23T00:15:40.511791Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_tfidf = vec_tfidf.fit_transform(afrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:16:14.111499Z",
     "start_time": "2018-11-23T00:15:40.706683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 50.18%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 46.3%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 47.89%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 48.59%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 43.66%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 47.18%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 50.0%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.33%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_tfidf, asentimentos))\n",
    "        matriz_resultados['tfidf'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA (usando TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:16:20.033706Z",
     "start_time": "2018-11-23T00:16:14.113478Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 40.32%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 44.72%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 47.36%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 47.18%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 40.85%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 46.13%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 48.06%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.33%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=70, n_iter=50, random_state=0)\n",
    "normalizer = MinMaxScaler(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "X_svd = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_svd, asentimentos))\n",
    "        matriz_resultados['tfidf+lsa'][classifier.__class__.__name__] = acc\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (usando TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:16:46.544331Z",
     "start_time": "2018-11-23T00:16:20.035889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 31.16%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 24.12%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 31.34%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 31.34%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 30.99%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 31.16%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 30.99%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.33%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=70, max_iter=50, random_state=0, n_jobs=5)\n",
    "normalizer = MinMaxScaler(copy=False)\n",
    "lda = make_pipeline(lda, normalizer)\n",
    "X_lda = lda.fit_transform(X_tfidf)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_lda, asentimentos))\n",
    "        matriz_resultados['tfidf+lda'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:16:46.639296Z",
     "start_time": "2018-11-23T00:16:46.547642Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_count = CountVectorizer(ngram_range=(1, 2))\n",
    "X_count = vec_count.fit_transform(afrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:17:07.632623Z",
     "start_time": "2018-11-23T00:16:46.641039Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 48.59%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 41.02%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 48.06%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 48.59%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 34.33%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 44.89%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 47.54%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.33%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_count, asentimentos))\n",
    "        matriz_resultados['count'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA (usando Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:17:13.846386Z",
     "start_time": "2018-11-23T00:17:07.634710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 36.8%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 37.85%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 45.95%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 44.89%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 39.08%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 45.6%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 46.48%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.33%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=70, n_iter=50, random_state=0)\n",
    "normalizer = MinMaxScaler(copy=False)\n",
    "lda = make_pipeline(svd, normalizer)\n",
    "X_svd = lda.fit_transform(X_count)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_svd, asentimentos))\n",
    "        matriz_resultados['count+lsa'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (usando Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:17:37.418865Z",
     "start_time": "2018-11-23T00:17:13.848629Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : MultinomialNB\n",
      "Acurácia : 30.99%\n",
      "--------------------\n",
      "Modelo   : ComplementNB\n",
      "Acurácia : 21.3%\n",
      "--------------------\n",
      "Modelo   : LogisticRegression\n",
      "Acurácia : 30.81%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 31.69%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 30.99%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 32.39%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 28.87%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.33%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=70, max_iter=50, random_state=0, n_jobs=5)\n",
    "normalizer = MinMaxScaler(copy=False)\n",
    "lda = make_pipeline(lda, normalizer)\n",
    "X_lda = lda.fit_transform(X_count)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X_lda, asentimentos))\n",
    "        matriz_resultados['count+lda'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count + TF-IDF + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:20:53.130266Z",
     "start_time": "2018-11-23T00:17:37.421623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23382912, 24849000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count\n",
    "vec_count = CountVectorizer()\n",
    "X_count = vec_count.fit_transform(afrases)\n",
    "weights_count = pd.DataFrame(np.round(X_count.toarray().T, 8), index=vec_count.get_feature_names())\n",
    "\n",
    "# TF-IDF\n",
    "vec_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vec_tfidf.fit_transform(afrases)\n",
    "weights_tfidf = pd.DataFrame(np.round(X_tfidf.toarray().T, 8), index=vec_tfidf.get_feature_names())\n",
    "\n",
    "# Word2Vec preprocessing\n",
    "frases_w2v = []\n",
    "for frase in afrases:\n",
    "    bigram = []\n",
    "    p_frase = word_tokenize(frase)\n",
    "    for m, palavra in enumerate(p_frase):\n",
    "        next_p = None\n",
    "        try:\n",
    "            next_p = p_frase[m+1]\n",
    "        except:\n",
    "            pass\n",
    "        bigram += [f'{palavra}']\n",
    "#         if next_p:\n",
    "#             bigram += [f'{palavra} {next_p}']\n",
    "    frases_w2v += [bigram]\n",
    "\n",
    "# Word2Vec\n",
    "model = gensim.models.Word2Vec(\n",
    "    sentences=frases_w2v,\n",
    "    sg=1,\n",
    "    hs=1,\n",
    "    size=1,\n",
    "    window=25,\n",
    "    min_count=1,\n",
    "    seed=0,\n",
    "    workers=10)\n",
    "model.train(frases_w2v, total_examples=len(frases_w2v), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:20:54.158241Z",
     "start_time": "2018-11-23T00:20:53.132773Z"
    }
   },
   "outputs": [],
   "source": [
    "r_words = {}\n",
    "for word in vec_count.get_feature_names():\n",
    "    idx = weights_count.index.get_loc(word)\n",
    "    w2c_val = .1\n",
    "    try:\n",
    "        w2c_val = model.wv[word]\n",
    "    except:\n",
    "        pass\n",
    "    r_words[word] = (weights_tfidf.iloc[idx].values + weights_count.iloc[idx].values) * w2c_val\n",
    "lwor = list(r_words.keys())\n",
    "X = np.asarray(list(r_words.values()))\n",
    "weights = pd.DataFrame(X, index=lwor)\n",
    "X = X.T\n",
    "\n",
    "normalizer = Normalizer(copy=False)\n",
    "X = normalizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:21:25.478086Z",
     "start_time": "2018-11-23T00:20:54.160386Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : LogisticRegression\n",
      "Acurácia : 48.94%\n",
      "--------------------\n",
      "Modelo   : RandomForestClassifier\n",
      "Acurácia : 48.94%\n",
      "--------------------\n",
      "Modelo   : KNeighborsClassifier\n",
      "Acurácia : 44.54%\n",
      "--------------------\n",
      "Modelo   : MLPClassifier\n",
      "Acurácia : 42.96%\n",
      "--------------------\n",
      "Modelo   : LinearSVC\n",
      "Acurácia : 47.36%\n",
      "--------------------\n",
      "Modelo   : SVC\n",
      "Acurácia : 34.33%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    try:\n",
    "        acc = run_ml_model(classifier, **split_data(X, asentimentos))\n",
    "        matriz_resultados['tfidf+count+w2c'][classifier.__class__.__name__] = acc\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado dos Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T00:47:08.544186Z",
     "start_time": "2018-11-23T00:47:08.485326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row2_col1 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row2_col4 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row3_col6 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row5_col0 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row5_col3 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row6_col3 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row6_col6 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row7_col2 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }    #T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row7_col5 {\n",
       "            background-color:  green;\n",
       "             color:  white;\n",
       "             font-weight:  bold;\n",
       "        }</style>  \n",
       "<table id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >tfidf</th> \n",
       "        <th class=\"col_heading level0 col1\" >tfidf+lsa</th> \n",
       "        <th class=\"col_heading level0 col2\" >tfidf+lda</th> \n",
       "        <th class=\"col_heading level0 col3\" >count</th> \n",
       "        <th class=\"col_heading level0 col4\" >count+lsa</th> \n",
       "        <th class=\"col_heading level0 col5\" >count+lda</th> \n",
       "        <th class=\"col_heading level0 col6\" >tfidf+count+w2c</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0level0_row0\" class=\"row_heading level0 row0\" >ComplementNB</th> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row0_col0\" class=\"data row0 col0\" >46.30%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row0_col1\" class=\"data row0 col1\" >44.72%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row0_col2\" class=\"data row0 col2\" >24.12%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row0_col3\" class=\"data row0 col3\" >41.02%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row0_col4\" class=\"data row0 col4\" >37.85%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row0_col5\" class=\"data row0 col5\" >21.30%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row0_col6\" class=\"data row0 col6\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0level0_row1\" class=\"row_heading level0 row1\" >KNeighborsClassifier</th> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row1_col0\" class=\"data row1 col0\" >43.66%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row1_col1\" class=\"data row1 col1\" >40.85%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row1_col2\" class=\"data row1 col2\" >30.99%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row1_col3\" class=\"data row1 col3\" >34.33%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row1_col4\" class=\"data row1 col4\" >39.08%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row1_col5\" class=\"data row1 col5\" >30.99%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row1_col6\" class=\"data row1 col6\" >44.54%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0level0_row2\" class=\"row_heading level0 row2\" >LinearSVC</th> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row2_col0\" class=\"data row2 col0\" >50.00%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row2_col1\" class=\"data row2 col1\" >48.06%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row2_col2\" class=\"data row2 col2\" >30.99%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row2_col3\" class=\"data row2 col3\" >47.54%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row2_col4\" class=\"data row2 col4\" >46.48%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row2_col5\" class=\"data row2 col5\" >28.87%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row2_col6\" class=\"data row2 col6\" >47.36%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0level0_row3\" class=\"row_heading level0 row3\" >LogisticRegression</th> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row3_col0\" class=\"data row3 col0\" >47.89%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row3_col1\" class=\"data row3 col1\" >47.36%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row3_col2\" class=\"data row3 col2\" >31.34%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row3_col3\" class=\"data row3 col3\" >48.06%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row3_col4\" class=\"data row3 col4\" >45.95%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row3_col5\" class=\"data row3 col5\" >30.81%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row3_col6\" class=\"data row3 col6\" >48.94%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0level0_row4\" class=\"row_heading level0 row4\" >MLPClassifier</th> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row4_col0\" class=\"data row4 col0\" >47.18%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row4_col1\" class=\"data row4 col1\" >46.13%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row4_col2\" class=\"data row4 col2\" >31.16%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row4_col3\" class=\"data row4 col3\" >44.89%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row4_col4\" class=\"data row4 col4\" >45.60%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row4_col5\" class=\"data row4 col5\" >32.39%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row4_col6\" class=\"data row4 col6\" >42.96%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0level0_row5\" class=\"row_heading level0 row5\" >MultinomialNB</th> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row5_col0\" class=\"data row5 col0\" >50.18%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row5_col1\" class=\"data row5 col1\" >40.32%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row5_col2\" class=\"data row5 col2\" >31.16%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row5_col3\" class=\"data row5 col3\" >48.59%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row5_col4\" class=\"data row5 col4\" >36.80%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row5_col5\" class=\"data row5 col5\" >30.99%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row5_col6\" class=\"data row5 col6\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0level0_row6\" class=\"row_heading level0 row6\" >RandomForestClassifier</th> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row6_col0\" class=\"data row6 col0\" >48.59%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row6_col1\" class=\"data row6 col1\" >47.18%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row6_col2\" class=\"data row6 col2\" >31.34%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row6_col3\" class=\"data row6 col3\" >48.59%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row6_col4\" class=\"data row6 col4\" >44.89%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row6_col5\" class=\"data row6 col5\" >31.69%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row6_col6\" class=\"data row6 col6\" >48.94%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0level0_row7\" class=\"row_heading level0 row7\" >SVC</th> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row7_col0\" class=\"data row7 col0\" >34.33%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row7_col1\" class=\"data row7 col1\" >34.33%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row7_col2\" class=\"data row7 col2\" >34.33%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row7_col3\" class=\"data row7 col3\" >34.33%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row7_col4\" class=\"data row7 col4\" >34.33%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row7_col5\" class=\"data row7 col5\" >34.33%</td> \n",
       "        <td id=\"T_41dc1eae_ef40_11e8_9ccd_f04da2e514e0row7_col6\" class=\"data row7 col6\" >34.33%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7febbc02b2e8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(matriz_resultados)\n",
    "df.style.apply(highlight_max).format({\n",
    "    'tfidf': '{:,.2f}%'.format,\n",
    "    'tfidf+lsa': '{:,.2f}%'.format,\n",
    "    'tfidf+lda': '{:,.2f}%'.format,\n",
    "    'count': '{:,.2f}%'.format,\n",
    "    'count+lsa': '{:,.2f}%'.format,\n",
    "    'count+lda': '{:,.2f}%'.format,\n",
    "    'tfidf+count+w2c': '{:,.2f}%'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo escolhido e salvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo   : CalibratedClassifierCV\n",
      "Acurácia : 54.01%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_emotions.sav']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_tfidf = vec_tfidf.fit_transform(afrases)\n",
    "\n",
    "svd = TruncatedSVD(n_components=70, n_iter=50, random_state=0)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "X_svd = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "svm = LinearSVC(max_iter=1200)\n",
    "model = CalibratedClassifierCV(svm) \n",
    "model.fit(X_svd, asentimentos)\n",
    "\n",
    "accuracy = np.round(model.score(X_svd, asentimentos) * 100, 2)\n",
    "print(f'Modelo   : {model.__class__.__name__}')\n",
    "print(f'Acurácia : {accuracy}%')\n",
    "\n",
    "filename = 'tfidf_emotions.sav'\n",
    "joblib.dump(vec_tfidf, filename)\n",
    "\n",
    "filename = 'lsa_emotions.sav'\n",
    "joblib.dump(lsa, filename)\n",
    "\n",
    "filename = 'model_emotions.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12, 12.71, 37.2, 9.19, 2.56, 8.02, 0.12, 30.08]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict_proba(X_svd)\n",
    "list(np.round(y[0] * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "31px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
